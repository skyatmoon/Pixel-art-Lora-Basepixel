{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/WSH032/kohya-config-webui/blob/main/kohya_train_webui.ipynb","timestamp":1682469046019}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium"},"cells":[{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","!echo \"google drive connected.\"\n","\n","!pip install gradio > /dev/null 2>&1\n","!apt -qq install liblz4-tool aria2  > /dev/null 2>&1\n","\n","%cd /content\n","!git clone https://github.com/kohya-ss/sd-scripts.git"],"metadata":{"id":"sGDquRQCOMzv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682573059453,"user_tz":300,"elapsed":48994,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"fa44697d-e8e5-4220-df98-17d837e07022"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","google drive connected.\n","/content\n","Cloning into 'sd-scripts'...\n","remote: Enumerating objects: 2468, done.\u001b[K\n","remote: Counting objects: 100% (596/596), done.\u001b[K\n","remote: Compressing objects: 100% (112/112), done.\u001b[K\n","remote: Total 2468 (delta 509), reused 511 (delta 484), pack-reused 1872\u001b[K\n","Receiving objects: 100% (2468/2468), 3.15 MiB | 18.75 MiB/s, done.\n","Resolving deltas: 100% (1688/1688), done.\n"]}]},{"cell_type":"code","source":["use_data_dir_self = True\n","copy_reg = False \n","\n","train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\"\n","reg_data_dir_self = \"\"\n","\n","train_data_dir = \"/content/train/data\"\n","reg_data_dir = \"/content/train/reg\"\n","\n","if use_data_dir_self:\n","  print(f\"custom path:\")\n","else:\n","  train_data_dir_self = \"/content/drive/MyDrive/Lora/input/\"\n","  reg_data_dir_self = \"/content/drive/MyDrive/Lora/reg/\"\n","print(f\"path:{train_data_dir_self}\")\n","\n","!mkdir -p /content/lora-scripts/train/\n","!rm -r /content/lora-scripts/train/\n","\n","print(\"copying...\")\n","!mkdir -p {train_data_dir}\n","!cp -r {train_data_dir_self}/* {train_data_dir}\n","!echo \"copy completed.\"\n","\n","if copy_reg:\n","  print(f\"path for reg:{reg_data_dir_self}\")\n","  print(\"copy reg\")\n","  !mkdir -p {reg_data_dir}\n","  !cp -r {reg_data_dir_self}/* {reg_data_dir}\n","  !echo \"copy reg completed.\"\n","else:\n","  print(\"no reg\")\n"],"metadata":{"id":"EzHADOPZMlN4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682573070443,"user_tz":300,"elapsed":5515,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"b267e9f7-be23-4b19-ccd3-f7558a0a65a3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["custom path:\n","path:/content/drive/MyDrive/Lora/input/\n","copying...\n","copy completed.\n","no reg\n"]}]},{"cell_type":"code","source":["installModels = []\n","installv2Models = []\n","\n","modelName = \"Stable-Diffusion-v1-5\"\n","\n","base_model_url = \"\"\n","\n","base_model_self_dir = \"\"\n","\n","base_model_extension = \"ckpt\"\n","\n","\n","modelUrl = [\n","    \"\",\n","    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n","    \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n","    \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\",\n","    \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n","    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n","    \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n","    \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n","]\n","modelList = [\n","    \"\",\n","    \"Animefull-final-pruned\",\n","    \"Anything-v3-1\",\n","    \"AnyLoRA\",\n","    \"AnimePastelDream\",    \n","    \"Chillout-mix\",\n","    \"OpenJourney-v4\",\n","    \"Stable-Diffusion-v1-5\",\n","]\n","v2ModelUrl = [\n","    \"\",\n","    \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n","    \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n","    \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n","    \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n","    \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n","    \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n","    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n","    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n","    \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n","]\n","v2ModelList = [\n","    \"\",\n","    \"stable-diffusion-2-1-base\",\n","    \"stable-diffusion-2-1-768v\",\n","    \"plat-diffusion-v1-3-1\",\n","    \"replicant-v1\",\n","    \"illuminati-diffusion-v1-0\",\n","    \"illuminati-diffusion-v1-1\",\n","    \"waifu-diffusion-1-4-anime-e2\",\n","    \"waifu-diffusion-1-5-e2\",\n","    \"waifu-diffusion-1-5-e2-aesthetic\",\n","]\n","if modelName:\n","    installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n","\n","\n","base_model_dir = \"/content/sd-models/\"\n","\n","def check_ext(url):\n","  if url.endswith(\".ckpt\"):\n","    return \"ckpt\"\n","  elif url.endswith(\".safetensors\"):\n","    return \"safetensors\"\n","  else:\n","    return base_model_extension\n","\n","def install(checkpoint_name, url):\n","    ext = check_ext(url)\n","    hf_token = \"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\"\n","    user_header = f'\"Authorization: Bearer {hf_token}\"'\n","    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {checkpoint_name}.{ext} {url}\n","    return f\"{checkpoint_name}.{ext}\"\n","def install_checkpoint():\n","    for model in installModels:\n","        return install(model[0], model[1])\n","    for v2model in installv2Models:\n","        return install(v2model[0], v2model[1])\n","\n","base_model_name = install_checkpoint()\n","if base_model_name:\n","  pretrained_model = base_model_dir + base_model_name\n","else:\n","  if base_model_url:\n","    base_model_name = \"download.\" + check_ext(base_model_url)\n","    pretrained_model = base_model_dir + base_model_name\n","    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {base_model_dir} -o {base_model_name} --allow-overwrite {base_model_url}\n","  else:\n","    if base_model_self_dir:\n","      base_model_name = \"self.\" + check_ext(base_model_self_dir)\n","      pretrained_model = base_model_dir + base_model_name\n","      !cp {base_model_self_dir} {pretrained_model}\n","    else:\n","      print(\"no model\")\n","\n","print(f\"model used: {base_model_name}\")\n"],"metadata":{"id":"OYGUN309MuUJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682573104881,"user_tz":300,"elapsed":20109,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"51f3866b-9628-4c2a-f540-7b9415bd3656"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[" *** Download Progress Summary as of Thu Apr 27 05:24:54 2023 *** \n","=\n","[#a6ab36 2.3GiB/3.9GiB(59%) CN:16 DL:238MiB ETA:6s]\n","FILE: /content/sd-models//Stable-Diffusion-v1-5.safetensors\n","-\n","\n","\u001b[0m\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","a6ab36|\u001b[1;32mOK\u001b[0m  |   212MiB/s|/content/sd-models//Stable-Diffusion-v1-5.safetensors\n","\n","Status Legend:\n","(OK):download completed.\n","model used: Stable-Diffusion-v1-5.safetensors\n"]}]},{"cell_type":"code","source":["installVae = []\n","vaeUrl = [\n","    \"\",\n","    \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n","    \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n","    \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n","]\n","vaeList = [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n","vaeName = \"anime.vae.pt\"\n","\n","installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n","\n","vae_dir = \"/content/vae/\"\n","def install(vae_name, url):\n","    hf_token = \"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\"\n","    user_header = f'\"Authorization: Bearer {hf_token}\"'\n","    !aria2c --console-log-level=error --allow-overwrite --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vae_dir} -o \"vae.pt\" \"{url}\"\n","\n","def install_vae():\n","    if vaeName != \"none\":\n","        for vae in installVae:\n","            install(vae[0], vae[1])\n","    else:\n","        pass\n","install_vae()\n"],"metadata":{"id":"hiA3z5rPNriX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682542100758,"user_tz":300,"elapsed":2143,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"4f93403d-2f0d-4f6b-ed2b-b03226863b2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r\r\u001b[0m\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","73f7b8|\u001b[1;32mOK\u001b[0m  |   445MiB/s|/content/vae//vae.pt\n","\n","Status Legend:\n","(OK):download completed.\n"]}]},{"cell_type":"code","source":["import os\n","import toml\n","import warnings\n","import gradio as gr\n","\n","common_parameter_dict_key_list=[]\n","sample_parameter_dict_key_list=[]\n","plus_parameter_dict_key_list=[]\n","\n","common_parameter_dict=({})\n","sample_parameter_dict=({})\n","plus_parameter_dict=({})\n","\n","random_symbol = '\\U0001f3b2\\ufe0f'  # 🎲️\n","reuse_symbol = '\\u267b\\ufe0f'  # ♻️\n","paste_symbol = '\\u2199\\ufe0f'  # ↙\n","refresh_symbol = '\\U0001f504'  # 🔄\n","save_style_symbol = '\\U0001f4be'  # 💾\n","apply_style_symbol = '\\U0001f4cb'  # 📋\n","clear_prompt_symbol = '\\U0001f5d1\\ufe0f'  # 🗑️\n","extra_networks_symbol = '\\U0001F3B4'  # 🎴\n","switch_values_symbol = '\\U000021C5' # ⇅\n","folder_symbol = '\\U0001f4c2'  # 📂\n","\n","parameter_len_dict={\"common\":0, \"sample\":0, \"plus\":0}\n","\n","def check_len_and_2dict(args, parameter_len_dict_value, parameter_dict_key_list, func_name=\"\"):\n","    if len(args) != parameter_len_dict_value:\n","        warnings.warn(f\"传入{func_name}的参数长度不匹配\", UserWarning)\n","    if len(parameter_dict_key_list) != parameter_len_dict_value:\n","        warnings.warn(f\" {func_name}内部字典赋值关键字列表的长度不匹配\", UserWarning)\n","    parameter_dict = dict(zip(parameter_dict_key_list, args))\n","    return parameter_dict\n","\n","def common_parameter_get(*args):\n","    global common_parameter_dict\n","    common_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"common\"], common_parameter_dict_key_list, func_name=\"common_parameter_get\")\n","    common_parameter_toml = toml.dumps(common_parameter_dict)\n","    common_parameter_title = \"基础参数配置确认\"\n","    return common_parameter_toml,  common_parameter_title\n","\n","def sample_parameter_get(*args):\n","    global sample_parameter_dict\n","    sample_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"sample\"], sample_parameter_dict_key_list, func_name=\"sample_parameter_get\")\n","    sample_parameter_toml = toml.dumps(sample_parameter_dict)\n","    sample_parameter_title = \"采样配置确认\"\n","    return sample_parameter_toml,  sample_parameter_title\n","\n","\n","def plus_parameter_get(*args):\n","    global plus_parameter_dict\n","    plus_parameter_dict = check_len_and_2dict(args, parameter_len_dict[\"plus\"], plus_parameter_dict_key_list, func_name=\"plus_parameter_get\")\n","    plus_parameter_toml = toml.dumps(plus_parameter_dict)\n","    plus_parameter_title = \"进阶参数配置确认\"\n","    return plus_parameter_toml,  plus_parameter_title\n","\n","\n","def all_parameter_get(*args):\n","    if len(args) != sum( parameter_len_dict.values() ):\n","         warnings.warn(f\"传入all_parameter_get的参数长度不匹配\", UserWarning)\n","    common_parameter_toml,  common_parameter_title = common_parameter_get( *args[ : parameter_len_dict[\"common\"] ] )\n","    sample_parameter_toml,  sample_parameter_title = sample_parameter_get( *args[ parameter_len_dict[\"common\"] : parameter_len_dict[\"common\"] + parameter_len_dict[\"sample\"] ] )\n","    plus_parameter_toml,  plus_parameter_title = plus_parameter_get( *args[ -parameter_len_dict[\"plus\"] : ] )\n","    return common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  \"全部参数确认\"\n","\n","def model_get(model_dir):\n","    model_dir = model_dir if model_dir else os.getcwd()\n","    files = [f for f in os.listdir(model_dir) if os.path.isfile(os.path.join(model_dir, f))]\n","    if files:\n","        return model_dir, gr.update( choices=files,value=files[0] )\n","    else:\n","        return model_dir, gr.update( choices=[],value=\"\" )\n","\n","def write_files(write_files_dir):\n","    write_files_dir = write_files_dir if write_files_dir else os.getcwd()\n","    os.makedirs(write_files_dir, exist_ok=True)\n","    config_file_toml_path = os.path.join(write_files_dir, \"config_file.toml\")\n","    sample_prompts_txt_path = os.path.join(write_files_dir, \"sample_prompts.txt\")\n","\n","    all = {**common_parameter_dict, **sample_parameter_dict, **plus_parameter_dict}\n","\n","    def parameter2toml():\n","\n","        #生成config_file.toml的字典\n","\n","        #model_arguments部分\n","        model_arguments = { key: all.get(key) for key in [\"v2\", \"v_parameterization\"] }\n","        \"\"\" 生成底模路径 \"\"\"\n","        base_model_path = os.path.join( all.get(\"base_model_dir\"), all.get(\"base_model_name\") )\n","        model_arguments.update( {\"pretrained_model_name_or_path\": base_model_path} )\n","        \"\"\" 生成vae路径 \"\"\"\n","        if all.get(\"use_vae\"):\n","            vae_model_path = os.path.join( all.get(\"vae_model_dir\"), all.get(\"vae_model_name\") )\n","            model_arguments.update( {\"vae\": vae_model_path} )\n","\n","        #additional_network_arguments部分\n","        additional_network_arguments = { key: all.get(key) for key in [\"unet_lr\", \"text_encoder_lr\", \"network_dim\",\\\n","                                            \"network_alpha\", \"network_train_unet_only\",\\\n","                                            \"network_train_text_encoder_only\"] }\n","        \"\"\" 生成如network_module = \"locon.locon_kohya\" \"\"\"\n","        #[\"LoRA-LierLa\", \"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\", \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]\n","        #主要负责network_module的参数生成\n","        def network_module_param(train_method):\n","            conv_dim = all.get(\"conv_dim\") if train_method != \"DyLoRa-C3Lier\" else all.get(\"network_dim\")\n","            conv_alpha = all.get(\"conv_alpha\")\n","            algo = \"lora\" if train_method == \"LoCon_Lycoris\" else \"loha\"\n","            unit = all.get(\"unit\")\n","            if train_method in [\"LoRA-LierLa\", \"LoRA-C3Lier\"]:\n","                network_module = \"networks.lora\"\n","                if train_method == \"LoRA-C3Lier\":\n","                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n","                else:\n","                    network_module_args = []\n","            elif train_method in [\"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n","                network_module = \"lycoris.kohya\"\n","                network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"algo={algo}\"]\n","            elif train_method in [\"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"]:\n","                network_module = \"networks.dylora\"\n","                if train_method == \"DyLoRa-C3Lier\":\n","                    network_module_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\", f\"unit={unit}\"]\n","                else:\n","                    network_module_args = [f\"unit={unit}\"]\n","            else: \n","                warnings.warn(f\"训练方法参数生成出错\", UserWarning)\n","            return network_module, network_module_args\n","        network_module, network_module_args = network_module_param( all.get(\"train_method\") )\n","        #更多network_args部分（主要为分层训练）\n","        network_lr_weight_args = [ f\"{name}={all.get(name)}\" for name in [\"up_lr_weight\", \"mid_lr_weight\", \"down_lr_weight\"] if all.get(name) ]\n","\n","        def network_block_param(train_method):\n","            lst = [\"block_dims\", \"block_alphas\", \"conv_block_dims\", \"conv_block_alphas\"]\n","            if train_method == \"LoRA-LierLa\":\n","                return [ f\"{name}={all.get(name)}\" for name in lst[0:1] if all.get(name) ]\n","            if train_method in [\"LoRA-C3Lier\", \"LoCon_Lycoris\", \"LoHa_Lycoris\"]:\n","                return [ f\"{name}={all.get(name)}\" for name in lst if all.get(name) ]\n","            else:\n","                return []\n","        network_block_args = network_block_param( all.get(\"train_method\") )\n","        \n","\n","        network_args = []\n","        network_args.extend(network_module_args)\n","        network_args.extend(network_lr_weight_args)\n","        network_args.extend(network_block_args)\n","\n","        additional_network_arguments.update( { \"network_module\":network_module } )\n","        additional_network_arguments.update( {\"network_args\":network_args} )          \n","\n","        #optimizer_arguments部分\n","        optimizer_arguments = { key: all.get(key) for key in [\"optimizer_type\", \"lr_scheduler\", \"lr_warmup_steps\"] }\n","        \"\"\"只有余弦重启调度器指定重启次数\"\"\"\n","        if all.get(\"lr_scheduler\") == \"cosine_with_restarts\":\n","            optimizer_arguments.update( {\"lr_restart_cycles\":all.get(\"lr_restart_cycles\")} )\n","        \"\"\"学习率lr指定=unet_lr\"\"\"\n","        optimizer_arguments.update( {\"learning_rate\":all.get(\"unet_lr\")} )\n","            #optimizer_args（待添加）\n","\n","        #dataset_arguments部分\n","        dataset_arguments = {\"cache_latents\":True,\n","                    \"shuffle_caption\":True,\n","                    \"enable_bucket\":True\n","        }\n","\n","        #training_arguments部分\n","        training_arguments = { key: all.get(key) for key in [\"batch_size\", \"noise_offset\", \"keep_tokens\",\\\n","                                      \"min_bucket_reso\", \"max_bucket_reso\",\\\n","                                      \"caption_extension\", \"max_token_length\", \"seed\",\\\n","                                      \"xformers\", \"lowram\"]\n","        }\n","        \"\"\"min_snr_gamma大于零才生效\"\"\"\n","        if all.get(\"min_snr_gamma\") > 0:\n","            training_arguments.update( { \"min_snr_gamma\":all.get(\"min_snr_gamma\") } )\n","        \"\"\" 最大训练时间 \"\"\"\n","        training_arguments.update( { all.get(\"max_train_method\"):all.get(\"max_train_value\") } )\n","        \"\"\" 训练分辨率 \"\"\"\n","        training_arguments.update( { \"resolution\":f\"{all.get('width')},{all.get('height')}\" } )\n","        \"\"\" 如果v2开启，则不指定clip_skip \"\"\"\n","        if not all.get(\"v2\"):\n","            training_arguments.update( { \"clip_skip\":all.get(\"clip_skip\") } )\n","        \"\"\" 重训练模块 \"\"\"\n","        if all.get(\"use_retrain\") == \"model\":\n","            training_arguments.update( { \"network_weights\":all.get(\"retrain_dir\") } )\n","        elif all.get(\"use_retrain\") == \"state\":\n","            training_arguments.update( { \"resume\":all.get(\"retrain_dir\") } )\n","        \"\"\"  训练精度、保存精度 \"\"\"\n","        training_arguments.update( { \"mixed_precision\":\"fp16\" } )\n","        training_arguments.update( { \"save_precision\":\"fp16\" } )\n","        \n","\n","\n","        #sample_prompt_arguments部分（采样间隔，采样文件地址待添加）\n","        sample_prompt_arguments = { key: all.get(key) for key in [\"sample_sampler\"] }\n","        sample_prompt_arguments.update( {all.get(\"sample_every_n_type\"):all.get(\"sample_every_n_type_value\")} )\n","\n","        #dreambooth_arguments部分\n","        dreambooth_arguments = { key: all.get(key) for key in [\"train_data_dir\", \"reg_data_dir\", \"prior_loss_weight\"] }\n","\n","        #saving_arguments部分\n","        saving_arguments = { key: all.get(key) for key in [\"output_dir\",\\\n","                                      \"output_name\", \"save_every_n_epochs\", \"save_n_epoch_ratio\",\\\n","                                      \"save_last_n_epochs\", \"save_state\", \"save_model_as\" ]\n","        }\n","        \"\"\" 指定log输出目录与output相同 \"\"\"\n","        saving_arguments.update( { \"logging_dir\":os.path.join( all.get(\"output_dir\"), \"logs\" ) } )\n","        \"\"\" 指定log前缀和输出名字相同 \"\"\"\n","        saving_arguments.update( { \"log_prefix\":all.get(\"output_name\") } )\n","        \n","\n","        toml_dict = {\"model_arguments\":model_arguments,\n","               \"additional_network_arguments\":additional_network_arguments,\n","               \"optimizer_arguments\":optimizer_arguments,\n","               \"dataset_arguments\":dataset_arguments,\n","               \"training_arguments\":training_arguments,\n","               \"sample_prompt_arguments\":sample_prompt_arguments,\n","               \"dreambooth_arguments\":dreambooth_arguments,\n","               \"saving_arguments\":saving_arguments,\n","        }\n","        toml_str = toml.dumps(toml_dict)\n","        return toml_str\n","    def sample_parameter2txt():\n","        #key_list = [\"prompt\", \"negative\", \"sample_width\", \"sample_height\", \"sample_scale\", \"sample_steps\", \"sample_seed\"]\n","        sample_str = f\"\"\"{all.get(\"prompt\")}  \\\n","--n {all.get(\"negative\")}  \\\n","--w {all.get(\"sample_width\")}  \\\n","--h {all.get(\"sample_height\")}  \\\n","--l {all.get(\"sample_scale\")}  \\\n","--s {all.get(\"sample_steps\")}  \\\n","{f\"--d {all.get('sample_seed')}\" if all.get('sample_seed') > 0 else \"\"}\"\"\"\n","\n","        return sample_str\n","\n","    def write(content, path):\n","        with open(path, \"w\", encoding=\"utf-8\") as f:\n","            f.write(content)\n","\n","    write(parameter2toml(), config_file_toml_path)\n","    write(sample_parameter2txt(), sample_prompts_txt_path)\n","    write_files_title = f\"写入成功,输出文件在{write_files_dir}：config_file.toml和sample_prompts.txt\"\n","    return write_files_title\n","\n","with gr.Blocks() as demo:\n","    with gr.Row():\n","        write_files_button = gr.Button(\"生成toml参数与采样配置文件\")\n","        all_parameter_get_button = gr.Button(\"全部参数确认\")\n","        write_files_dir = gr.Textbox(lines=1, label=\"写入文件夹\", placeholder=\"文件夹路径,不填就默认为当前文件夹\", value=\"\")\n","    write_files_title = gr.Markdown(\"生成适用于kohya/train_network.py的配置文件\")\n","    with gr.Tabs():\n","        with gr.TabItem(\"基础参数\"):\n","            common_parameter_get_button = gr.Button(\"确定\")\n","            common_parameter_title = gr.Markdown(\"\")\n","            with gr.Accordion(\"当前基础参数配置\", open=False):\n","                common_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"基础参数\", value=\"\")\n","            with gr.Row():\n","                train_data_dir = gr.Textbox(lines=1, label=\"train_data_dir\", placeholder=\"训练集路径\")\n","            with gr.Accordion(\"使用正则化(可选)\", open=False):\n","                with gr.Row():\n","                    reg_data_dir = gr.Textbox(lines=1, label=\"reg_data_dir\", placeholder=\"正则化集路径（填入意味着启用正则化）\")\n","                    prior_loss_weight = gr.Slider(0, 1, step=0.01, value=0.3, label=\"正则化权重\")\n","            with gr.Row():\n","                base_model_dir = gr.Textbox(label=\"底模文件夹地址\", placeholder=\"文件夹路径,不填就默认为当前文件夹\")\n","                base_model_get_button = gr.Button(reuse_symbol)\n","                base_model_name = gr.Dropdown(choices=[],label=\"底模\",value=\"\")\n","            with gr.Accordion(\"使用vae(可选)\", open=False):\n","                with gr.Row():\n","                    vae_model_dir = gr.Textbox(label=\"vae文件夹地址\", placeholder=\"文件夹路径,不填就默认为当前文件夹\")\n","                    vae_model_get_button = gr.Button(reuse_symbol)\n","                    vae_model_name = gr.Dropdown(choices=[],label=\"vae\",value=\"\")\n","                    use_vae = gr.Checkbox(label=\"是否使用vae\",value=False)\n","            with gr.Row():\n","                width = gr.Slider(64, 1920, step=64, value=512, label=\"训练分辨率（宽）width\")\n","                height = gr.Slider(64, 1920, step=64, value=512, label=\"训练分辨率（高）height\")\n","                batch_size = gr.Slider(1, 24, step=1, value=1, label=\"batch大小\")\n","            with gr.Row():\n","                noise_offset = gr.Slider(0, 1, step=0.01, value=0.05, label=\"noise_offset\")\n","                keep_tokens = gr.Slider(0, 225, step=1, value=0, label=\"keep_tokens\")\n","                min_snr_gamma = gr.Slider(0, 100, step=0.1, value=5, label=\"min_snr_gamma`设置为0则不生效`\")\n","            \"\"\"\n","            with gr.Row():\n","                gr.Markdown(\"repeat * 图片数 = 每个epoch的steps数\")\n","            \"\"\"\n","            with gr.Row():\n","                max_train_method = gr.Dropdown([\"max_train_epochs\",\"max_train_steps\"], label=\"以epochs或steps来指定最大训练时间\", value=\"max_train_epochs\")\n","                max_train_value = gr.Number(label=\"最大训练epochs\\steps数\", value=10, precision=0)\n","            with gr.Accordion(\"输出设置\", open=True):\n","                with gr.Row():\n","                    output_dir = gr.Textbox( label=\"模型、log日志输出地址（自行修改）\", placeholder=\"文件夹路径\",value=os.path.join(os.getcwd(),\"output\") )\n","                    output_name = gr.Textbox(label=\"输出模型名称（自行修改）\", placeholder=\"名称\",value=\"output_name\")\n","                    save_model_as = gr.Dropdown([\"safetensors\",\"ckpt\",\"pt\"], label=\"保存模型格式\", value=\"safetensors\")\n","                with gr.Row():\n","                    save_every_n_epochs = gr.Slider(1, 499, step=1, value=1, label=\"每n个epoch保存一次\")\n","                    save_n_epoch_ratio = gr.Slider(1, 499, step=1, value=0, label=\"等间隔保存n个(如不指定为0，将会覆盖每n个epoch保存一次)\")\n","                    save_last_n_epochs = gr.Slider(1, 499, step=1, value=499, label=\"最多保存n个（后面的出来就会把前面删了,优先级最高）\")\n","                    save_state = gr.Checkbox(label=\"保存学习状态\",value=False)\n","            with gr.Row():\n","                optimizer_type = gr.Dropdown([\"AdamW8bit\", \"Lion\", \"DAdaptation\", \"AdamW\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"],\\\n","                                label=\"optimizer_type优化器类型\", value=\"AdamW8bit\")\n","                unet_lr = gr.Number(label=\"unet学习率\", value=1e-4)\n","                text_encoder_lr = gr.Number(label=\"text_encoder学习率\", value=1e-5)\n","            with gr.Row():\n","                lr_scheduler = gr.Dropdown([\"cosine_with_restarts\",\"cosine\",\"polynomial\",\"linear\",\"constant_with_warmup\",\"constant\"],\\\n","                               label=\"lr_scheduler学习率调度器\", value=\"cosine_with_restarts\")\n","                lr_warmup_steps = gr.Number(label=\"升温步数\", value=0, precision=0)\n","                lr_restart_cycles = gr.Number(label=\"退火重启次数\", value=1, precision=0)\n","            with gr.Row():\n","                train_method = gr.Dropdown([\"LoRA-LierLa\", \"LoRA-C3Lier\",\\\n","                                \"LoCon_Lycoris\",\"LoHa_Lycoris\",\\\n","                                \"DyLoRa-LierLa\", \"DyLoRa-C3Lier\"],\\\n","                                label=\"train_method训练方法\", value=\"LoRA-LierLa\")\n","                network_dim = gr.Number(label=\"线性dim\", value=32, precision=0)\n","                network_alpha = gr.Number(label=\"线性alpha（可以为小数）\", value=16)\n","            with gr.Accordion(\"额外网络参数(LoRA-C3Lier、LoCon、LoHa、DyLoRa-C3Lier都属于卷积,unit为两个DyLoRa专用)\", open=True):\n","                with gr.Row():\n","                    with gr.Column():\n","                        conv_dim = gr.Number(label=\"卷积dim\", info=\"使用DyLoRa-C3Lier时会被设置为等于基础dim\", value=8, precision=0)\n","                    with gr.Column():\n","                        conv_alpha = gr.Number(label=\"卷积alpha\", info=\"可以为小数\", value=1)\n","                    with gr.Column():\n","                        unit = gr.Number(label=\"分割单位unit(整数)\", info=\"使用DyLoRa时，请让dim为unit的倍数\", value=1, precision=0)\n","            with gr.Row():          \n","                v2 = gr.Checkbox(label=\"v2\")\n","                v_parameterization = gr.Checkbox(label=\"v_parameterization\")\n","                lowram = gr.Checkbox(label=\"lowram\")\n","                xformers = gr.Checkbox(label=\"xformers\",value=True)\n","        with gr.TabItem(\"采样参数\"):\n","            sample_parameter_get_button = gr.Button(\"确定\")\n","            sample_parameter_title = gr.Markdown(\"\")\n","            with gr.Accordion(\"当前采样配置\", open=False):\n","                sample_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"采样配置\", value=\"\")\n","            with gr.Row():\n","                #enable_sample = gr.Checkbox(label=\"是否启用采样功能\")\n","                sample_every_n_type = gr.Dropdown([\"sample_every_n_epochs\", \"sample_every_n_steps\"], label=\"sample_every_n_type\", value=\"sample_every_n_epochs\")\n","                sample_every_n_type_value = gr.Number(label=\"sample_every_n_type_value\", value=1, precision=0)\n","            with gr.Row():\n","                sample_sampler = gr.Dropdown([\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\",\\\n","                            \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\",\\\n","                            \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"],\\\n","                            label=\"采样器\", value=\"euler_a\")\n","                sample_width = gr.Slider(64, 1920, step=64, value=512, label=\"采样图片宽\")\n","                sample_height = gr.Slider(64, 1920, step=64, value=768, label=\"采样图片高\")\n","                sample_scale = gr.Slider(1, 30, step=0.5, value=7, label=\"提示词相关性\")\n","                sample_seed = gr.Number(label=\"采样种子(-1不是随机，大于0才生效)\", value=-1, precision=0)\n","                sample_steps = gr.Slider(1, 150, step=1, value=24, label=\"采样迭代步数\")\n","            with gr.Row():\n","                prompt = gr.Textbox(lines=10, label=\"prompt\", placeholder=\"正面提示词\", value=\"(masterpiece, best quality, hires:1.2), 1girl, solo,\")\n","                default_negative = (\"(worst quality, bad quality:1.4), \"\n","                          \"lowres, bad anatomy, bad hands, text, error, \"\n","                          \"missing fingers, extra digit, fewer digits, \"\n","                          \"cropped, worst quality, low quality, normal quality, \"\n","                          \"jpeg artifacts,signature, watermark, username, blurry,\")\n","                negative = gr.Textbox(lines=10, label=\"negative\", placeholder=\"负面提示词\", value=default_negative)\n","        with gr.TabItem(\"进阶参数\"):\n","            plus_parameter_get_button = gr.Button(\"确定\")\n","            plus_parameter_title = gr.Markdown(\"\")\n","            with gr.Accordion(\"当前进阶参数配置\", open=False):\n","                plus_parameter_toml = gr.Textbox(label=\"toml形式\", placeholder=\"进阶参数\", value=\"\")\n","            with gr.Row():\n","                use_retrain = gr.Dropdown([\"no\",\"model\",\"state\"], label=\"是否使用重训练\", value=\"no\")\n","                retrain_dir = gr.Textbox(lines=1, label=\"重训练路径\", placeholder=\"模型或者状态路径\", value=\"\")\n","            with gr.Row():\n","                min_bucket_reso = gr.Slider(64, 1920, step=64, value=256, label=\"最低桶分辨率\")\n","                max_bucket_reso = gr.Slider(64, 1920, step=64, value=1024, label=\"最高桶分辨率\")\n","                clip_skip = gr.Slider(0, 25, step=1, value=2, label=\"跳过层数\")\n","                caption_extension = gr.Textbox(lines=1, label=\"标签文件扩展名\", placeholder=\"一般填.txt或.cap\", value=\".txt\")\n","                max_token_length = gr.Slider(75, 225, step=75, value=225, label=\"训练最大token数\")\n","                seed = gr.Number(label=\"种子\", value=1337, precision=0)\n","            with gr.Row():\n","                network_train_unet_only= gr.Checkbox(label=\"仅训练unet网络\",value=False)\n","                network_train_text_encoder_only = gr.Checkbox(label=\"仅训练text_encoder网络\",value=False)\n","            with gr.Accordion(\"分层学习模块\", open=True):\n","                gr.Markdown(\"学习率分层，为不同层的结构指定不同学习率倍数\")\n","                with gr.Row():\n","                    with gr.Column(scale=15):\n","                        up_lr_weight = gr.Textbox(lines=1, label=\"上层学习率权重\", placeholder=\"留空则不启用\",\\\n","                                      info=\"15层，例如1.5,1.5,1.5,1.5,1.0,1.0,1.0,1.0,0.5,0.5,0.5,0.5\", value=\"\")\n","                    with gr.Column(scale=1):\n","                        mid_lr_weight = gr.Textbox(lines=1, label=\"中层学习率权重\", placeholder=\"留空则不启用\",\\\n","                                      info=\"1层，例如2.0\", value=\"\")\n","                    with gr.Column(scale=15):\n","                        down_lr_weight = gr.Textbox(lines=1, label=\"下层学习率权重\", placeholder=\"留空则不启用\",\\\n","                                      info=\"15层，例如0.5,0.5,0.5,0.5,1.0,1.0,1.0,1.0,1.5,1.5,1.5,1.5\", value=\"\")\n","                gr.Markdown(\"dim和alpha分层，为不同层的结构指定不同的dim和alpha（`DyLoRa`无法使用，卷积分层只有`LoRa-C3Lier、LoCon、LoHa`可以使用）\")\n","                with gr.Row():\n","                        block_dims = gr.Textbox(lines=1, label=\"线性dim分层\", placeholder=\"留空则不启用\",\\\n","                                      info=\"25层（上中下），例如2,4,4,4,8,8,8,8,12,12,12,12,16,12,12,12,12,8,8,8,8,4,4,4,2\", value=\"\")\n","                        block_alphas = gr.Textbox(lines=1, label=\"线性alpha分层\", placeholder=\"留空则不启用\",\\\n","                                      info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n","                with gr.Row():\n","                        conv_block_dims = gr.Textbox(lines=1, label=\"卷积dim分层\", placeholder=\"留空则不启用\",\\\n","                                        info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n","                        conv_block_alphas = gr.Textbox(lines=1, label=\"卷积alpha分层\", placeholder=\"留空则不启用\",\\\n","                                        info=\"25层（上中下），例如2,2,2,2,4,4,4,4,6,6,6,6,8,6,6,6,6,4,4,4,4,2,2,2,2\", value=\"\")\n","\n","\n","    def dict_key_list_2_list(dict_key_list):\n","        list = []\n","        for key in dict_key_list:\n","            try:\n","                list.append(globals()[key])\n","            except KeyError:\n","                print(f\"Error: parameter_dict_key_list中{key}不存在\")\n","        list_len = len(list)\n","        return list, list_len\n","\n","    common_parameter_dict_key_list = [\"train_data_dir\",\n","                      \"reg_data_dir\",\n","                      \"prior_loss_weight\",\n","                      \"base_model_dir\",\n","                      \"base_model_name\",\n","                      \"vae_model_dir\",\n","                      \"vae_model_name\",\n","                      \"use_vae\",\n","                      \"width\",\n","                      \"height\",\n","                      \"batch_size\",\n","                      \"noise_offset\",\n","                      \"keep_tokens\",\n","                      \"min_snr_gamma\",\n","                      \"max_train_method\",\n","                      \"max_train_value\",\n","                      \"output_dir\",\n","                      \"output_name\",\n","                      \"save_model_as\",\n","                      \"save_every_n_epochs\",\n","                      \"save_n_epoch_ratio\",\n","                      \"save_last_n_epochs\",\n","                      \"save_state\",\n","                      \"optimizer_type\",\n","                      \"unet_lr\",\n","                      \"text_encoder_lr\",\n","                      \"lr_scheduler\",\n","                      \"lr_warmup_steps\",\n","                      \"lr_restart_cycles\",\n","                      \"train_method\",\n","                      \"network_dim\",\n","                      \"network_alpha\",\n","                      \"conv_dim\",\n","                      \"conv_alpha\",\n","                      \"unit\",\n","                      \"v2\",\n","                      \"v_parameterization\",\n","                      \"lowram\",\n","                      \"xformers\"]\n","    common_parameter_list, parameter_len_dict[\"common\"] = dict_key_list_2_list(common_parameter_dict_key_list)\n","    sample_parameter_dict_key_list = [\"sample_every_n_type\",\n","                      \"sample_every_n_type_value\",\n","                      \"sample_sampler\",\n","                      \"sample_width\",\n","                      \"sample_height\",\n","                      \"sample_scale\",\n","                      \"sample_seed\",\n","                      \"sample_steps\",\n","                      \"prompt\",\n","                      \"negative\"]\n","    sample_parameter_list, parameter_len_dict[\"sample\"] = dict_key_list_2_list(sample_parameter_dict_key_list)\n","    plus_parameter_dict_key_list = [\"use_retrain\",\n","                    \"retrain_dir\",\n","                    \"min_bucket_reso\",\n","                    \"max_bucket_reso\",\n","                    \"clip_skip\",\n","                    \"caption_extension\",\n","                    \"max_token_length\",\n","                    \"seed\",\n","                    \"network_train_unet_only\",\n","                    \"network_train_text_encoder_only\",\n","                    \"up_lr_weight\",\n","                    \"mid_lr_weight\",\n","                    \"down_lr_weight\",\n","                    \"block_dims\",\n","                    \"block_alphas\",\n","                    \"conv_block_dims\",\n","                    \"conv_block_alphas\"]\n","    plus_parameter_list, parameter_len_dict[\"plus\"] = dict_key_list_2_list(plus_parameter_dict_key_list)\n","    all_parameter_list = common_parameter_list + sample_parameter_list + plus_parameter_list\n","\n","    common_parameter_get_button.click(fn=common_parameter_get,\n","                    inputs=common_parameter_list,\n","                    outputs=[common_parameter_toml,  common_parameter_title]\n","                    )\n","    sample_parameter_get_button.click(fn=sample_parameter_get,\n","                    inputs=sample_parameter_list,\n","                    outputs=[sample_parameter_toml,  sample_parameter_title]\n","                    )\n","    plus_parameter_get_button.click(fn=plus_parameter_get,\n","                    inputs=plus_parameter_list,\n","                    outputs=[plus_parameter_toml,  plus_parameter_title]\n","                    )\n","    all_parameter_get_button.click(fn=all_parameter_get,\n","                    inputs=all_parameter_list,\n","                    outputs=[common_parameter_toml, sample_parameter_toml, plus_parameter_toml,  write_files_title]\n","                    )\n","    base_model_get_button.click(fn=model_get,inputs=base_model_dir,outputs=[base_model_dir, base_model_name])\n","    vae_model_get_button.click(fn=model_get,inputs=vae_model_dir,outputs=[vae_model_dir, vae_model_name])\n","    write_files_button.click(fn=write_files, inputs=[write_files_dir], outputs=[write_files_title])\n","\n","\n","if __name__ == \"__main__\":\n","    demo.launch(share=False,inbrowser=False,inline=True,debug=False)"],"metadata":{"id":"6ikbBvFSRQ7B","colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"status":"ok","timestamp":1682542375928,"user_tz":300,"elapsed":1606,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"c44f9b74-074f-40ac-fc40-871d922fa1e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}}]},{"cell_type":"code","source":["#@title pip relaited packedges\n","\n","!sudo apt-get update -y > /dev/null 2>&1\n","!sudo apt-get install python3.10 > /dev/null 2>&1\n","#change alternatives \n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1  > /dev/null 2>&1\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2  > /dev/null 2>&1\n","#check python version \n","!python --version\n","\n","# install pip for new python \n","!sudo apt-get install python3.10-distutils  > /dev/null 2>&1\n","!wget https://bootstrap.pypa.io/get-pip.py  > /dev/null 2>&1\n","!python get-pip.py  > /dev/null 2>&1\n","#install colab's dependencies \n","!python -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor  > /dev/null 2>&1\n","# link to the old google package \n","!ln -s /usr/local/lib/python3.9/dist-packages/google \\\n","/usr/local/lib/python3.10/dist-packages/google  > /dev/null 2>&1\n","\n","%cd sd-scripts\n","!pip -q install --upgrade -r requirements.txt\n","!pip -q install xformers==0.0.17\n","\n","!pip -q install triton==2.0.0\n","\n","!pip -q install --upgrade lion-pytorch lycoris-lora\n","\n","\n","!pip -q install dadaptation\n","\n","#tensorboard\n","%load_ext tensorboard"],"metadata":{"id":"mxO7gAHILhZx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682573499077,"user_tz":300,"elapsed":366504,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"7324501d-774a-44f6-81e8-853406c7e40f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n","/content/sd-scripts\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.6/769.6 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["#@title  ### Train\n","\n","%cd /content/sd-scripts\n","!export TF_CPP_MIN_LOG_LEVEL=3\n","!accelerate launch --num_cpu_threads_per_process 8 train_network.py --config_file=\"config_file.toml\" --sample_prompts=\"sample_prompts.txt\" \n","\n","\n","!echo \"Completed.\""],"metadata":{"id":"NTRgMI7jR3DY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682546149636,"user_tz":300,"elapsed":3624897,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"b7e6bf09-ee07-4f87-b340-e62a479de846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/sd-scripts\n","2023-04-26 20:55:26.163650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-26 20:55:26.322555: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-04-26 20:55:26.362653: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-04-26 20:55:26.998585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-04-26 20:55:26.998739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-04-26 20:55:26.998761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `1`\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","2023-04-26 20:55:29.640491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-26 20:55:29.801070: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-04-26 20:55:29.839342: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-04-26 20:55:30.464096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-04-26 20:55:30.464214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-04-26 20:55:30.464235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Loading settings from config_file.toml...\n","config_file\n","prepare tokenizer\n","Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 3.37MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 2.56MB/s]\n","Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 382kB/s]\n","Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 928kB/s]\n","update token length: 225\n","Use DreamBooth method.\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: .git\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: library.egg-info\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: networks\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: library\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: tools\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: .github\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: bitsandbytes_windows\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: finetune\n","ignore directory without repeats / 繰り返し回数のないディレクトリを無視します: build\n","prepare images.\n","found directory /content/train/data/5_basepixel contains 100 image files\n","500 train images with repeating.\n","0 reg images.\n","no regularization images / 正則化画像が見つかりませんでした\n","[Dataset 0]\n","  batch_size: 1\n","  resolution: (512, 512)\n","  enable_bucket: True\n","  min_bucket_reso: 256\n","  max_bucket_reso: 1024\n","  bucket_reso_steps: 64\n","  bucket_no_upscale: False\n","\n","  [Subset 0 of Dataset 0]\n","    image_dir: \"/content/train/data/5_basepixel\"\n","    image_count: 100\n","    num_repeats: 5\n","    shuffle_caption: True\n","    keep_tokens: 0\n","    caption_dropout_rate: 0.0\n","    caption_dropout_every_n_epoches: 0\n","    caption_tag_dropout_rate: 0.0\n","    color_aug: False\n","    flip_aug: False\n","    face_crop_aug_range: None\n","    random_crop: False\n","    token_warmup_min: 1,\n","    token_warmup_step: 0,\n","    is_reg: False\n","    class_tokens: basepixel\n","    caption_extension: .txt\n","\n","\n","[Dataset 0]\n","loading image sizes.\n","100% 100/100 [00:00<00:00, 11248.40it/s]\n","make buckets\n","number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n","bucket 0: resolution (512, 512), count: 500\n","mean ar error (without repeats): 0.0\n","prepare accelerator\n","Using accelerator 0.15.0 or above.\n","loading model for process 0/1\n","load StableDiffusion checkpoint\n","/usr/local/lib/python3.10/dist-packages/safetensors/torch.py:98: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  with safe_open(filename, framework=\"pt\", device=device) as f:\n","/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","/usr/local/lib/python3.10/dist-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  storage = cls(wrap_storage=untyped_storage)\n","loading u-net: <All keys matched successfully>\n","loading vae: <All keys matched successfully>\n","Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 3.57MB/s]\n","Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:05<00:00, 304MB/s]\n","loading text encoder: <All keys matched successfully>\n","load VAE: /content/vae/vae.pt\n","additional VAE loaded\n","Replace CrossAttention.forward to use xformers\n","[Dataset 0]\n","caching latents.\n","100% 100/100 [00:04<00:00, 21.30it/s]\n","import network module: networks.lora\n","create LoRA network. base dim (rank): 128, alpha: 64.0\n","create LoRA for Text Encoder: 72 modules.\n","create LoRA for U-Net: 192 modules.\n","enable LoRA for text encoder\n","enable LoRA for U-Net\n","prepare optimizer, data loader etc.\n","\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n","================================================================================\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/python3.10/dist-packages/cv2/../../lib64')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//172.28.0.1'), PosixPath('8013')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-33vrc3fwli5tv --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n","  warn(\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n","CUDA SETUP: Detected CUDA version 118\n","CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n","use 8-bit AdamW optimizer | {}\n","override steps. steps for 20 epochs is / 指定エポックまでのステップ数: 10000\n","running training / 学習開始\n","  num train images * repeats / 学習画像の数×繰り返し回数: 500\n","  num reg images / 正則化画像の数: 0\n","  num batches per epoch / 1epochのバッチ数: 500\n","  num epochs / epoch数: 20\n","  batch size per device / バッチサイズ: 1\n","  gradient accumulation steps / 勾配を合計するステップ数 = 1\n","  total optimization steps / 学習ステップ数: 10000\n","steps:   0% 0/10000 [00:00<?, ?it/s]epoch 1/20\n","/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n","steps:   5% 500/10000 [02:56<55:49,  2.84it/s, loss=0.0746]epoch 2/20\n","steps:  10% 1000/10000 [05:52<52:49,  2.84it/s, loss=0.0687]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000002.safetensors\n","epoch 3/20\n","steps:  15% 1500/10000 [08:48<49:54,  2.84it/s, loss=0.0627]epoch 4/20\n","steps:  20% 2000/10000 [11:44<46:58,  2.84it/s, loss=0.0712]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000004.safetensors\n","epoch 5/20\n","steps:  25% 2500/10000 [14:41<44:05,  2.83it/s, loss=0.0645]generating sample images at step / サンプル画像生成 ステップ: 2500\n","prompt: basepixel, (masterpiece, best quality, hires:1.2), 1girl, solo, \n","negative_prompt: (worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, \n","height: 768\n","width: 512\n","sample_steps: 24\n","scale: 7.0\n","\n","  0% 0/24 [00:00<?, ?it/s]\u001b[A\n","  4% 1/24 [00:00<00:05,  3.95it/s]\u001b[A\n"," 12% 3/24 [00:00<00:02,  7.19it/s]\u001b[A\n"," 21% 5/24 [00:00<00:02,  8.54it/s]\u001b[A\n"," 29% 7/24 [00:00<00:01,  9.26it/s]\u001b[A\n"," 38% 9/24 [00:01<00:01,  9.66it/s]\u001b[A\n"," 46% 11/24 [00:01<00:01,  9.92it/s]\u001b[A\n"," 54% 13/24 [00:01<00:01, 10.08it/s]\u001b[A\n"," 62% 15/24 [00:01<00:00, 10.20it/s]\u001b[A\n"," 71% 17/24 [00:01<00:00, 10.28it/s]\u001b[A\n"," 79% 19/24 [00:01<00:00, 10.34it/s]\u001b[A\n"," 88% 21/24 [00:02<00:00, 10.34it/s]\u001b[A\n","100% 24/24 [00:02<00:00,  9.73it/s]\n","epoch 6/20\n","steps:  30% 3000/10000 [17:42<41:18,  2.82it/s, loss=0.0629]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000006.safetensors\n","epoch 7/20\n","steps:  35% 3500/10000 [20:39<38:22,  2.82it/s, loss=0.0632]epoch 8/20\n","steps:  40% 4000/10000 [23:36<35:25,  2.82it/s, loss=0.0631]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000008.safetensors\n","epoch 9/20\n","steps:  45% 4500/10000 [26:33<32:27,  2.82it/s, loss=0.0606]epoch 10/20\n","steps:  50% 5000/10000 [29:30<29:30,  2.82it/s, loss=0.0608]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000010.safetensors\n","generating sample images at step / サンプル画像生成 ステップ: 5000\n","prompt: basepixel, (masterpiece, best quality, hires:1.2), 1girl, solo, \n","negative_prompt: (worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, \n","height: 768\n","width: 512\n","sample_steps: 24\n","scale: 7.0\n","\n","  0% 0/24 [00:00<?, ?it/s]\u001b[A\n","  4% 1/24 [00:00<00:02,  8.92it/s]\u001b[A\n","  8% 2/24 [00:00<00:02,  9.32it/s]\u001b[A\n"," 17% 4/24 [00:00<00:02,  9.81it/s]\u001b[A\n"," 21% 5/24 [00:00<00:01,  9.85it/s]\u001b[A\n"," 29% 7/24 [00:00<00:01,  9.94it/s]\u001b[A\n"," 38% 9/24 [00:00<00:01, 10.05it/s]\u001b[A\n"," 46% 11/24 [00:01<00:01, 10.05it/s]\u001b[A\n"," 54% 13/24 [00:01<00:01, 10.10it/s]\u001b[A\n"," 62% 15/24 [00:01<00:00, 10.12it/s]\u001b[A\n"," 71% 17/24 [00:01<00:00, 10.04it/s]\u001b[A\n"," 79% 19/24 [00:01<00:00, 10.05it/s]\u001b[A\n"," 88% 21/24 [00:02<00:00, 10.01it/s]\u001b[A\n","100% 24/24 [00:02<00:00,  9.95it/s]\n","epoch 11/20\n","steps:  55% 5500/10000 [32:30<26:36,  2.82it/s, loss=0.0601]epoch 12/20\n","steps:  60% 6000/10000 [35:27<23:38,  2.82it/s, loss=0.0597]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000012.safetensors\n","epoch 13/20\n","steps:  65% 6500/10000 [38:24<20:41,  2.82it/s, loss=0.0542]epoch 14/20\n","steps:  70% 7000/10000 [41:22<17:43,  2.82it/s, loss=0.0592]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000014.safetensors\n","epoch 15/20\n","steps:  75% 7500/10000 [44:21<14:47,  2.82it/s, loss=0.0575]generating sample images at step / サンプル画像生成 ステップ: 7500\n","prompt: basepixel, (masterpiece, best quality, hires:1.2), 1girl, solo, \n","negative_prompt: (worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, \n","height: 768\n","width: 512\n","sample_steps: 24\n","scale: 7.0\n","\n","  0% 0/24 [00:00<?, ?it/s]\u001b[A\n","  4% 1/24 [00:00<00:02,  8.89it/s]\u001b[A\n","  8% 2/24 [00:00<00:02,  9.32it/s]\u001b[A\n"," 17% 4/24 [00:00<00:02,  9.78it/s]\u001b[A\n"," 25% 6/24 [00:00<00:01,  9.91it/s]\u001b[A\n"," 29% 7/24 [00:00<00:01,  9.91it/s]\u001b[A\n"," 33% 8/24 [00:00<00:01,  9.92it/s]\u001b[A\n"," 42% 10/24 [00:01<00:01, 10.01it/s]\u001b[A\n"," 50% 12/24 [00:01<00:01, 10.15it/s]\u001b[A\n"," 58% 14/24 [00:01<00:00, 10.24it/s]\u001b[A\n"," 67% 16/24 [00:01<00:00, 10.27it/s]\u001b[A\n"," 75% 18/24 [00:01<00:00, 10.30it/s]\u001b[A\n"," 83% 20/24 [00:01<00:00, 10.31it/s]\u001b[A\n"," 92% 22/24 [00:02<00:00, 10.34it/s]\u001b[A\n","100% 24/24 [00:02<00:00, 10.15it/s]\n","epoch 16/20\n","steps:  80% 8000/10000 [47:24<11:51,  2.81it/s, loss=0.0558]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000016.safetensors\n","epoch 17/20\n","steps:  85% 8500/10000 [50:25<08:53,  2.81it/s, loss=0.0588]epoch 18/20\n","steps:  90% 9000/10000 [53:25<05:56,  2.81it/s, loss=0.0552]saving checkpoint: /content/drive/MyDrive/Lora/basepixel-000018.safetensors\n","epoch 19/20\n","steps:  95% 9500/10000 [56:26<02:58,  2.81it/s, loss=0.0582]epoch 20/20\n","steps: 100% 10000/10000 [59:27<00:00,  2.80it/s, loss=0.0546]generating sample images at step / サンプル画像生成 ステップ: 10000\n","prompt: basepixel, (masterpiece, best quality, hires:1.2), 1girl, solo, \n","negative_prompt: (worst quality, bad quality:1.4), lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts,signature, watermark, username, blurry, \n","height: 768\n","width: 512\n","sample_steps: 24\n","scale: 7.0\n","\n","  0% 0/24 [00:00<?, ?it/s]\u001b[A\n","  4% 1/24 [00:00<00:02,  9.16it/s]\u001b[A\n","  8% 2/24 [00:00<00:02,  9.47it/s]\u001b[A\n"," 17% 4/24 [00:00<00:02,  9.91it/s]\u001b[A\n"," 25% 6/24 [00:00<00:01, 10.05it/s]\u001b[A\n"," 33% 8/24 [00:00<00:01, 10.16it/s]\u001b[A\n"," 42% 10/24 [00:00<00:01, 10.22it/s]\u001b[A\n"," 50% 12/24 [00:01<00:01, 10.23it/s]\u001b[A\n"," 58% 14/24 [00:01<00:00, 10.21it/s]\u001b[A\n"," 67% 16/24 [00:01<00:00, 10.25it/s]\u001b[A\n"," 75% 18/24 [00:01<00:00, 10.31it/s]\u001b[A\n"," 83% 20/24 [00:01<00:00, 10.35it/s]\u001b[A\n"," 92% 22/24 [00:02<00:00, 10.33it/s]\u001b[A\n","100% 24/24 [00:02<00:00, 10.21it/s]\n","saving checkpoint: /content/drive/MyDrive/Lora/basepixel.safetensors\n","model saved.\n","steps: 100% 10000/10000 [59:31<00:00,  2.80it/s, loss=0.0546]\n","Completed.\n"]}]},{"cell_type":"code","source":["!cp -ri /content/sd-scripts/* /content/drive/MyDrive/Lora/code/ "],"metadata":{"id":"tutfCrUlWXc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3LwfBtOkXKw","executionInfo":{"status":"ok","timestamp":1682546417254,"user_tz":300,"elapsed":111,"user":{"displayName":"Hongming Zhang","userId":"17412048167852921049"}},"outputId":"30f08a65-5d0f-49d9-d95d-0b828f1d358f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bitsandbytes_windows\tLICENSE.md\t       train_network.py\n","build\t\t\tnetworks\t       train_network_README-ja.md\n","config_file.toml\tREADME-ja.md\t       train_README-ja.md\n","config_README-ja.md\tREADME.md\t       train_README-zh.md\n","finetune\t\trequirements.txt       train_textual_inversion.py\n","fine_tune.py\t\tsample_prompts.txt     train_textual_inversion_XTI.py\n","fine_tune_README_ja.md\tsetup.py\t       train_ti_README-ja.md\n","gen_img_diffusers.py\ttools\t\t       _typos.toml\n","library\t\t\ttrain_db.py\t       XTI_hijack.py\n","library.egg-info\ttrain_db_README-ja.md\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YfCs09EBlcBg"},"execution_count":null,"outputs":[]}]}